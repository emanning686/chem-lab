{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85f2eb45-36ae-4625-a221-80a7d7649019",
   "metadata": {},
   "source": [
    "# Scikit-Learn and Scikit-Fingerprints Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfa83a-b5c2-4c6b-bb3d-5c7d5a051679",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook explores how the actively maintained Scikit-Fingerprints module can be used to blend BioInformatics with machine learning in Scikit-Learn\n",
    "\n",
    "### Questions\n",
    "\n",
    "How do we split data sets?\n",
    "How can we make a machine learning model most useful for future testing?\n",
    "What data can we extract from our test results?\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "* __Create and test a machine learning model__\n",
    "    * Import and split a data set\n",
    "    * Convert mols to fingerprints\n",
    "    * Train the model using 80% of the data\n",
    "    * Test the model's accuracy with the other 20% of the data\n",
    "* __Create a pipeline to:__\n",
    "    * Use Smiles as input\n",
    "    * Predict molecules\n",
    "\n",
    "### Purpose\n",
    "\n",
    "This notebook is designed to show how scientists can create machine learning models to aid with BioInformatics research without needing advanced knowledge of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da5ae3-8838-4442-84ff-17214e0104c3",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "A list of libraries that will need to be installed and imported to complete the tasks in the notebook.\n",
    "\n",
    "| Library | Contents | Source |\n",
    "| :-----: | :------- | :----- |\n",
    "| sklearn | library for creating and working with machine learning models| [Scikit-Learn documentation homepage](https://scikit-learn.org/stable/) |\n",
    "| skfp | library for working with molecular fingerprints with Scikit-Learn | [scikit-fingerprints on GitHub](https://github.com/scikit-fingerprints/scikit-fingerprints/tree/master) |\n",
    "| rdkit | libarary for cheminformatics and machine-learning modules | [rdkit documentation](https://www.rdkit.org/) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10422faa-2103-4bc8-9d5f-02d4e905c95a",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "These libraries will need to be installed in your computing environment to perform the tasks in this notebook.\n",
    "\n",
    "To install from the command line on your computer, use this command (with the `json` library as the example):\n",
    "\n",
    "`pip install json`\n",
    "\n",
    "To install from within a Jupyter notebook or CoLab notebook, you need to type the same command in a coding cell, preceded by an exclamation point.\n",
    "\n",
    "`!pip install json`\n",
    "\n",
    "These libraries will be imported as they are needed over the course of this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edae8a4-a3bb-4f47-a506-9a68a5a7f910",
   "metadata": {},
   "source": [
    "## Notebook Contents\n",
    "\n",
    "The next section of the notebook includes all of the raw code for this example. **Experienced coder** should use this as you see fit, either in this notebook or in your preferred environment.\n",
    "\n",
    "For **novice and intermediate coders**, the code is divided into sequential coding cells that each perform one step in the process. This notebook includes the following steps:\n",
    "\n",
    "1. Imports\n",
    "2. Load Data\n",
    "3. Convert Smiles to Mols - Split Training/Testing Data Sets\n",
    "4. Convert to Fingerprints\n",
    "5. Train Model and Predict Accuracy\n",
    "6. Test Predictions\n",
    "7. Create a Smiles Pipeline\n",
    "8. Test Pipeline Predictions\n",
    "9. Derive useful datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b9186-c308-41b8-a303-8f24775b526d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Full block of raw code for EXPERIENCED CODERS\n",
    "# scikit-learn imports\n",
    "from sklearn.ensemble import RandomForestClassifier # machine learning algorithm\n",
    "from sklearn.metrics import roc_auc_score # prediction accuracy scorer\n",
    "from sklearn.pipeline import make_pipeline # pipeline creater\n",
    "\n",
    "# scikit-fingerprints imports\n",
    "from skfp.datasets.moleculenet import load_hiv # built in test dataset\n",
    "from skfp.fingerprints import ECFPFingerprint # fingerprints type\n",
    "from skfp.model_selection import scaffold_train_test_split # train - test data split method\n",
    "from skfp.preprocessing import MolFromSmilesTransformer # SMILES to mol converter\n",
    "# other imports\n",
    "from rdkit import Chem # RdKit Chem module for manually creating Mol objects for testing\n",
    "\n",
    "smiles_list, y = load_hiv() # load the data from the scikit-fingerprints module\n",
    "print(\"SMILES:\")\n",
    "print(smiles_list[:3]) # display the first three SMILES loaded in the dataset\n",
    "print()\n",
    "print(\"Labels:\")\n",
    "print(y[:1000]) # display the first 1000 y values in the dataset\n",
    "\n",
    "mol_from_smiles = MolFromSmilesTransformer() # instantiate a SMILES to mols converter\n",
    "dataset_size = 5000 # cap the dataset to 5000 values for the sake of minimizing loading time\n",
    "mols = mol_from_smiles.transform(smiles_list[:dataset_size]) # transform the SMILES to mols\n",
    "mols_train, mols_test, y_train, y_test = scaffold_train_test_split(\n",
    "    mols, y[:dataset_size], test_size=0.2\n",
    ") # create training and testing subsets\n",
    "print(\"Molecules:\")\n",
    "print(mols_train[:3]) # print the first three converted mols in the training set\n",
    "\n",
    "ecfp_fp = ECFPFingerprint() # instantate a fingerprint creater\n",
    "X_train = ecfp_fp.transform(mols_train) # convert the X_training dataset from mols to fingerprints\n",
    "X_test = ecfp_fp.transform(mols_test) # convert the X_testing dataset from mols to fingerprints\n",
    "print(\"ECFP fingerprints:\")\n",
    "print(X_train.shape) # print the width and height of the X_training dataset\n",
    "print(X_train[:3]) # print the first three elements of the X_training dataset\n",
    "print(type(X_train)) # print the type of the dataset\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0) # instatiate the machine learning algorithm\n",
    "clf.fit(X_train, y_train) # fit the training dataset to the algorithm (all the actual machine learning happens in this line of code)\n",
    "\n",
    "clf.score(X_test, y_test) # score the dataset based on the accuracy of predictions of the testing dataset\n",
    "\n",
    "def predict(index): # function to display the accuracy of a prediction based on an index in the testing dataset\n",
    "    print(\"prediction: \" + str(clf.predict(X_test)[index]) + \", actual: \" + str(y_test[index]))\n",
    "\n",
    "# some sample tests to illustrate accuracy\n",
    "predict(5)\n",
    "predict(400)\n",
    "predict(852)\n",
    "predict(853)\n",
    "predict(849)\n",
    "\n",
    "smiles_pipeline = make_pipeline(\n",
    "    MolFromSmilesTransformer(),\n",
    "    ecfp_fp,\n",
    "    clf,\n",
    ") # create a pipeline to take SMILES strings, convert them to mols, convert the mols to fingerprints, and predict their value using the machine learning model we created\n",
    "\n",
    "# 1 Test\n",
    "mol = \"O=C(Nc1ccc(C2=NCCN2)cc1)Nc1cccc(C(=O)Nc2ccc(C3=NCCN3)cc2)c1\" # From HIV Test Dataset\n",
    "print(\"Smiles String: \" + mol)\n",
    "print(smiles_pipeline.predict([mol])[0])\n",
    "\n",
    "# 0 Test\n",
    "mol = \"CS(=O)(=O)NC(=O)c1cc(Oc2ccc(C(F)(F)F)cc2Cl)ccc1[N+](=O)[O-]\" # From TOX21 Test Dataset\n",
    "print(\"Smiles String: \" + mol)\n",
    "print(smiles_pipeline.predict([mol])[0])\n",
    "\n",
    "# Manual Entry\n",
    "mol = \"O=C(Nc1cccc(C(=O)Nc2ccc(C3=NCCN3)cc2)c1)c1ccc(C2=NCCN2)cc1\" # Random\n",
    "print(\"Smiles String: \" + mol)\n",
    "print(smiles_pipeline.predict([mol])[0])\n",
    "\n",
    "def perf_measure(y_actual, y_hat): # function to tally true positives, false positives, true negatives, and false negatives from the testing data\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)\n",
    "\n",
    "TP, FP, TN, FN = perf_measure(clf.predict(X_test), y_test) # find the tp, fp, tn, and fn values using the function\n",
    "print(f\"True Positives: {TP}\\nFalse Positives: {FP}\\nTrue Negatives: {TN}\\nFalse Negatives: {FN}\\n\")\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "print(f\"Sensitivity, hit rate, recall, or true positive rate: {TPR}\\nSpecificity or true negative rate: {TNR}\\nPrecision or positive predictive value: {PPV}\\nNegative predictive value: {NPV}\\nFall out or false positive rate: {FPR}\\nFalse negative rate: {FNR}\\nFalse discovery rate: {FDR}\\nOverall accuracy: {ACC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c23117-19d1-4686-b5a8-1872feed4250",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ee867-95c7-4460-9578-d44f96cb3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn imports\n",
    "from sklearn.ensemble import RandomForestClassifier # machine learning algorithm\n",
    "from sklearn.metrics import roc_auc_score # prediction accuracy scorer\n",
    "from sklearn.pipeline import make_pipeline # pipeline creater\n",
    "\n",
    "# scikit-fingerprints imports\n",
    "from skfp.datasets.moleculenet import load_hiv # built in test dataset\n",
    "from skfp.fingerprints import ECFPFingerprint # fingerprints type\n",
    "from skfp.model_selection import scaffold_train_test_split # train - test data split method\n",
    "from skfp.preprocessing import MolFromSmilesTransformer # SMILES to mol converter\n",
    "# other imports\n",
    "from rdkit import Chem # RdKit Chem module for manually creating Mol objects for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a83087-0697-42af-a724-9aed248d3359",
   "metadata": {},
   "source": [
    "### Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d52df-c75e-43d5-9a5f-1adedca89ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list, y = load_hiv() # load the data from the scikit-fingerprints module\n",
    "print(\"SMILES:\")\n",
    "print(smiles_list[:3]) # display the first three SMILES loaded in the dataset\n",
    "print()\n",
    "print(\"Labels:\")\n",
    "print(y[:1000]) # display the first 1000 y values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7cad4-80a9-44f9-bf4f-8871eb80d8d8",
   "metadata": {},
   "source": [
    "### Convert Smiles to Mols - Split Training/Testing Data Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7139dd2-5aaa-4491-a96e-f5f926eacd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_from_smiles = MolFromSmilesTransformer() # instantiate a SMILES to mols converter\n",
    "dataset_size = 5000 # cap the dataset to 5000 values for the sake of minimizing loading time\n",
    "mols = mol_from_smiles.transform(smiles_list[:dataset_size]) # transform the SMILES to mols\n",
    "mols_train, mols_test, y_train, y_test = scaffold_train_test_split(\n",
    "    mols, y[:dataset_size], test_size=0.2\n",
    ") # create training and testing subsets\n",
    "print(\"Molecules:\")\n",
    "print(mols_train[:3]) # print the first three converted mols in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a427de5c-2748-4544-a288-7d443b5517ce",
   "metadata": {},
   "source": [
    "### Convert to Fingerprints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68507c-b260-4afa-86a3-383e4912eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecfp_fp = ECFPFingerprint() # instantate a fingerprint creater\n",
    "X_train = ecfp_fp.transform(mols_train) # convert the X_training dataset from mols to fingerprints\n",
    "X_test = ecfp_fp.transform(mols_test) # convert the X_testing dataset from mols to fingerprints\n",
    "print(\"ECFP fingerprints:\")\n",
    "print(X_train.shape) # print the width and height of the X_training dataset\n",
    "print(X_train[:3]) # print the first three elements of the X_training dataset\n",
    "print(type(X_train)) # print the type of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446de17-a0b9-4cf2-8870-e5800d505c7f",
   "metadata": {},
   "source": [
    "### Train Model and Predict Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c368ce-3d5b-4776-a5d6-a29ede76ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0) # instatiate the machine learning algorithm\n",
    "clf.fit(X_train, y_train) # fit the training dataset to the algorithm (all the actual machine learning happens in this line of code)\n",
    "\n",
    "clf.score(X_test, y_test) # score the dataset based on the accuracy of predictions of the testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff06b4-b466-44d6-b93a-4b2558ba9af4",
   "metadata": {},
   "source": [
    "### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286f2a8-c6f9-4681-9b76-ce7dd71f9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(index): # function to display the accuracy of a prediction based on an index in the testing dataset\n",
    "    print(\"prediction: \" + str(clf.predict(X_test)[index]) + \", actual: \" + str(y_test[index]))\n",
    "\n",
    "# some sample tests to illustrate accuracy\n",
    "predict(5)\n",
    "predict(400)\n",
    "predict(852)\n",
    "predict(853)\n",
    "predict(849)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a179f00-aab1-49bc-9bbd-eaaed92a8f5f",
   "metadata": {},
   "source": [
    "### Create a Smiles Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff146740-93f8-4cc1-8c12-59c3c2e99b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_pipeline = make_pipeline(\n",
    "    MolFromSmilesTransformer(),\n",
    "    ecfp_fp,\n",
    "    clf,\n",
    ") # create a pipeline to take SMILES strings, convert them to mols, convert the mols to fingerprints, and predict their value using the machine learning model we created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf8b2a-a1e7-4c15-b3ba-a86b1ab5f9da",
   "metadata": {},
   "source": [
    "### Test Pipeline Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65241b-306c-40b3-864f-8a6fbd2e0fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Test\n",
    "mol = \"O=C(Nc1ccc(C2=NCCN2)cc1)Nc1cccc(C(=O)Nc2ccc(C3=NCCN3)cc2)c1\" # From HIV Test Dataset\n",
    "print(\"Smiles String: \" + mol)\n",
    "print(smiles_pipeline.predict([mol])[0])\n",
    "\n",
    "# 0 Test\n",
    "mol = \"CS(=O)(=O)NC(=O)c1cc(Oc2ccc(C(F)(F)F)cc2Cl)ccc1[N+](=O)[O-]\" # From TOX21 Test Dataset\n",
    "print(\"Smiles String: \" + mol)\n",
    "print(smiles_pipeline.predict([mol])[0])\n",
    "\n",
    "# Manual Entry\n",
    "mol = \"O=C(Nc1cccc(C(=O)Nc2ccc(C3=NCCN3)cc2)c1)c1ccc(C2=NCCN2)cc1\" # Random\n",
    "print(\"Smiles String: \" + mol)\n",
    "print(smiles_pipeline.predict([mol])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e8b4f4-ffca-4c5e-b537-666f2e92ec01",
   "metadata": {},
   "source": [
    "### Derive useful datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57830b-3efa-4aad-b541-c5b75bda5275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_hat): # function to tally true positives, false positives, true negatives, and false negatives from the testing data\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "           TP += 1\n",
    "        if y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_hat[i]==0:\n",
    "           TN += 1\n",
    "        if y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45627718-56c1-4f45-a63d-f75ea7df99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN = perf_measure(clf.predict(X_test), y_test) # find the tp, fp, tn, and fn values using the function\n",
    "print(f\"True Positives: {TP}\\nFalse Positives: {FP}\\nTrue Negatives: {TN}\\nFalse Negatives: {FN}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c921746-2c56-46ce-bea8-0579ce964793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ab1e7-2172-4237-bc46-e424baf922df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sensitivity, hit rate, recall, or true positive rate: {TPR}\\nSpecificity or true negative rate: {TNR}\\nPrecision or positive predictive value: {PPV}\\nNegative predictive value: {NPV}\\nFall out or false positive rate: {FPR}\\nFalse negative rate: {FNR}\\nFalse discovery rate: {FDR}\\nOverall accuracy: {ACC}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
